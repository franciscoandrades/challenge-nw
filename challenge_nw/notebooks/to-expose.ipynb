{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo de Juan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema\n",
    "\n",
    "El problema consiste en predecir la probabilidad de atraso de los vuelos que aterrizan o despegan del aeropuerto de Santiago\n",
    "de Chile (SCL). Para eso les entregamos un dataset usando datos públicos y reales donde cada fila corresponde a un vuelo\n",
    "que aterrizó o despegó de SCL. Para cada vuelo se cuenta con la siguiente información:\n",
    "\n",
    "* **Fecha-I** : Fecha y hora programada del vuelo.\n",
    "* **Vlo-I** : Número de vuelo programado.\n",
    "* **Ori-I** : Código de ciudad de origen programado.\n",
    "* **Des-I** : Código de ciudad de destino programado.\n",
    "* **Emp-I** : Código aerolínea de vuelo programado.\n",
    "* **Fecha-O** : Fecha y hora de operación del vuelo.\n",
    "* **Vlo-O** : Número de vuelo de operación del vuelo.\n",
    "* **Ori-O** : Código de ciudad de origen de operación\n",
    "* **Des-O** : Código de ciudad de destino de operación.\n",
    "* **Emp-O** : Código aerolínea de vuelo operado.\n",
    "* **DIA** : Día del mes de operación del vuelo.\n",
    "* **MES** : Número de mes de operación del vuelo.\n",
    "* **AÑO** : Año de operación del vuelo.\n",
    "* **DIANOM** : Día de la semana de operación del vuelo.\n",
    "* **TIPOVUELO** : Tipo de vuelo, I =Internacional, N =Nacional.\n",
    "* **OPERA** : Nombre de aerolínea que opera.\n",
    "* **SIGLAORI** : Nombre ciudad origen.\n",
    "* **SIGLADES** : Nombre ciudad destino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Obtención de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Se importan las librerías necesarias para el problema\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import missingno as msng\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/dataset_SCL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ¿Cómo se distribuyen los datos? ¿Qué te llama la atención o cuál es tu conclusión sobre esto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vuelos_aerolineas = df[\"OPERA\"].value_counts()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.barplot(x=vuelos_aerolineas.index, y=vuelos_aerolineas.values, alpha=0.9)\n",
    "plt.title(\"Cantidad de Vuelos por Aerlínea\")\n",
    "plt.ylabel(\"Número de Vuelos\", fontsize=12)\n",
    "plt.xlabel(\"Aerlínea\", fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vuelos_dia = df[\"DIA\"].value_counts()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.barplot(x=vuelos_dia.index, y=vuelos_dia.values, color=\"lightblue\", alpha=0.8)\n",
    "plt.title(\"Cantidad de Vuelos por día del Mes\")\n",
    "plt.ylabel(\"Número de Vuelos\", fontsize=12)\n",
    "plt.xlabel(\"Día del Mes\", fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vuelos_mes = df[\"MES\"].value_counts()\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.barplot(x=vuelos_mes.index, y=vuelos_mes.values, color=\"lightblue\", alpha=0.8)\n",
    "plt.title(\"Cantidad de Vuelos por día del Mes\")\n",
    "plt.ylabel(\"Número de Vuelos\", fontsize=12)\n",
    "plt.xlabel(\"Día del Mes\", fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vuelos = df[\"DIANOM\"].value_counts()\n",
    "dias = [\n",
    "    vuelos.index[2],\n",
    "    vuelos.index[5],\n",
    "    vuelos.index[4],\n",
    "    vuelos.index[1],\n",
    "    vuelos.index[0],\n",
    "    vuelos.index[6],\n",
    "    vuelos.index[3],\n",
    "]\n",
    "valores_dias = [\n",
    "    vuelos.values[2],\n",
    "    vuelos.values[5],\n",
    "    vuelos.values[4],\n",
    "    vuelos.values[1],\n",
    "    vuelos.values[0],\n",
    "    vuelos.values[6],\n",
    "    vuelos.values[3],\n",
    "]\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.barplot(x=dias, y=valores_dias, color=\"lightblue\", alpha=0.8)\n",
    "plt.title(\"Cantidad de Vuelos por Día de la Semana\")\n",
    "plt.ylabel(\"Número de Vuelos\", fontsize=12)\n",
    "plt.xlabel(\"Día de la Semana\", fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vuelos = df[\"TIPOVUELO\"].value_counts()\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.barplot(x=vuelos.index, y=vuelos.values, alpha=0.9)\n",
    "plt.title(\"Cantidad de Vuelos por Tipo de Vuelo\")\n",
    "plt.ylabel(\"Número de Vuelos\", fontsize=12)\n",
    "plt.xlabel(\"Tipo de Vuelo\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vuelos = df[\"SIGLADES\"].value_counts()\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.barplot(x=vuelos.index, y=vuelos.values, color=\"lightblue\", alpha=0.8)\n",
    "plt.title(\"Cantidad de Vuelos por Destino\")\n",
    "plt.ylabel(\"Número de Vuelos\", fontsize=12)\n",
    "plt.xlabel(\"Destino\", fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respecto a las distribuciones, se puede ver que dentro de todo la data está distribuida de manera bastante balanceada. De todas formas se pueden notar ciertas particularidades en algunas columnas: \n",
    "* En las aerolíneas LATAM Airlines es la con mayor cantidad de vuelo debido a que es la más grande aquí en chile y es la que tiene mayor cantidad de destinos. SKY Airlines sería la segunda más grande y de ahí en adelante las demás son bastante similares en cuanto a vuelos. \n",
    "* En cuanto a los días del mes, se puede ver como el día 31 tiene menor cantidad que los demás días y esto se puede deber a que hay menos días 31 durante el año.\n",
    "* Con los días de semana, el día sábado es el único en el que se nota una diferencia. Aquí puede ser porque la gente prefiere ese día para quedarse en donde sea que esté y aprovecharlo en caso que esté de viaje para poder recorrer o solamente descansar.\n",
    "* Por parte de los destinos se puede ver que gran parte se lo llevan las ciudades chilenas del norte. Esto puede ser por un alto flujo en minería."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Genera las columnas adicionales y luego expórtelas en un archivo synthetic_features.csv :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **temporada_alta** : 1 si **Fecha-I** está entre 15-Dic y 3-Mar, o 15-Jul y 31-Jul, o 11-Sep y 30-Sep, 0 si no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def temporada_alta(fecha):\n",
    "    fecha_año = int(fecha.split(\"-\")[0])\n",
    "    fecha = datetime.strptime(fecha, \"%Y-%m-%d %H:%M:%S\")\n",
    "    range1_min = datetime.strptime(\"15-Dec\", \"%d-%b\").replace(year=fecha_año)\n",
    "    range1_max = datetime.strptime(\"31-Dec\", \"%d-%b\").replace(year=fecha_año)\n",
    "    range2_min = datetime.strptime(\"1-Jan\", \"%d-%b\").replace(year=fecha_año)\n",
    "    range2_max = datetime.strptime(\"3-Mar\", \"%d-%b\").replace(year=fecha_año)\n",
    "    range3_min = datetime.strptime(\"15-Jul\", \"%d-%b\").replace(year=fecha_año)\n",
    "    range3_max = datetime.strptime(\"31-Jul\", \"%d-%b\").replace(year=fecha_año)\n",
    "    range4_min = datetime.strptime(\"11-Sep\", \"%d-%b\").replace(year=fecha_año)\n",
    "    range4_max = datetime.strptime(\"30-Sep\", \"%d-%b\").replace(year=fecha_año)\n",
    "\n",
    "    if (\n",
    "        (fecha >= range1_min and fecha <= range1_max)\n",
    "        or (fecha >= range2_min and fecha <= range2_max)\n",
    "        or (fecha >= range3_min and fecha <= range3_max)\n",
    "        or (fecha >= range4_min and fecha <= range4_max)\n",
    "    ):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"temporada_alta\"] = df[\"Fecha-I\"].apply(temporada_alta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"temporada_alta\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **dif_min** : diferencia en minutos entre **Fecha-O** y **Fecha-I** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dif_min(data):\n",
    "    fecha_o = datetime.strptime(data[\"Fecha-O\"], \"%Y-%m-%d %H:%M:%S\")\n",
    "    fecha_i = datetime.strptime(data[\"Fecha-I\"], \"%Y-%m-%d %H:%M:%S\")\n",
    "    dif_min = ((fecha_o - fecha_i).total_seconds()) / 60\n",
    "    return dif_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"dif_min\"] = df.apply(dif_min, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **atraso_15** : 1 si **dif_min** > 15, 0 si no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"atraso_15\"] = np.where(df[\"dif_min\"] > 15, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"atraso_15\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **periodo_dia** : mañana (entre 5:00 y 11:59), tarde (entre 12:00 y 18:59) y noche (entre 19:00 y 4:59), en base a **Fecha-I**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_periodo_dia(fecha):\n",
    "    fecha_time = datetime.strptime(fecha, \"%Y-%m-%d %H:%M:%S\").time()\n",
    "    mañana_min = datetime.strptime(\"05:00\", \"%H:%M\").time()\n",
    "    mañana_max = datetime.strptime(\"11:59\", \"%H:%M\").time()\n",
    "    tarde_min = datetime.strptime(\"12:00\", \"%H:%M\").time()\n",
    "    tarde_max = datetime.strptime(\"18:59\", \"%H:%M\").time()\n",
    "    noche_min1 = datetime.strptime(\"19:00\", \"%H:%M\").time()\n",
    "    noche_max1 = datetime.strptime(\"23:59\", \"%H:%M\").time()\n",
    "    noche_min2 = datetime.strptime(\"00:00\", \"%H:%M\").time()\n",
    "    noche_max2 = datetime.strptime(\"4:59\", \"%H:%M\").time()\n",
    "\n",
    "    if fecha_time > mañana_min and fecha_time < mañana_max:\n",
    "        return \"mañana\"\n",
    "    elif fecha_time > tarde_min and fecha_time < tarde_max:\n",
    "        return \"tarde\"\n",
    "    elif (fecha_time > noche_min1 and fecha_time < noche_max1) or (\n",
    "        fecha_time > noche_min2 and fecha_time < noche_max2\n",
    "    ):\n",
    "        return \"noche\"\n",
    "    return \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"periodo_dia\"] = df[\"Fecha-I\"].apply(get_periodo_dia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[[\"temporada_alta\", \"dif_min\", \"atraso_15\", \"periodo_dia\"]].to_csv(\n",
    "    \"../data/synthetic_features.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. ¿Cómo se compone la tasa de atraso por destino, aerolínea, mes del año, día de la semana, temporada, tipo de vuelo? ¿Qué variables esperarías que más influyeran en predecir atrasos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Cómo se compone la tasa de atraso por destino, aerolínea, mes del año, día de la semana, temporada, tipo de vuelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calcular_tasa(df, columna):\n",
    "\n",
    "    dic_atrasos = {}\n",
    "    for _, row in df.iterrows():\n",
    "        if row[\"atraso_15\"] == 1:\n",
    "            if row[columna] not in dic_atrasos:\n",
    "                dic_atrasos[row[columna]] = 1\n",
    "            else:\n",
    "                dic_atrasos[row[columna]] += 1\n",
    "\n",
    "    total_values = df[columna].value_counts()\n",
    "\n",
    "    dic_tasas = {}\n",
    "    for name, total in total_values.iteritems():\n",
    "        if name in dic_atrasos:\n",
    "            dic_tasas[name] = round(total / dic_atrasos[name], 2)\n",
    "        else:\n",
    "            dic_tasas[name] = 0\n",
    "\n",
    "    return pd.DataFrame.from_dict(data=dic_tasas, orient=\"index\", columns=[\"Tasa (%)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasas_destinos = calcular_tasa(df, \"SIGLADES\")\n",
    "tasas_destinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasas_destinos_values = df[\"SIGLADES\"].value_counts().index\n",
    "plt.figure(figsize=(20, 5))\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.barplot(\n",
    "    x=df[\"SIGLADES\"].value_counts().index, y=tasas_destinos[\"Tasa (%)\"], alpha=0.75\n",
    ")\n",
    "plt.title(\"Tasa de Retraso por Destino\")\n",
    "plt.ylabel(\"Tasa de Retraso [%]\", fontsize=12)\n",
    "plt.xlabel(\"Destino\", fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasas_aerolineas = calcular_tasa(df, \"OPERA\")\n",
    "tasas_aerolineas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasas_aerolineas_values = df[\"OPERA\"].value_counts().index\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.barplot(x=tasas_aerolineas_values, y=tasas_aerolineas[\"Tasa (%)\"], alpha=0.75)\n",
    "plt.title(\"Tasa de Retraso por Aerlínea\")\n",
    "plt.ylabel(\"Tasa de Retraso [%]\", fontsize=12)\n",
    "plt.xlabel(\"Aerolínea\", fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasas_meses = calcular_tasa(df, \"MES\")\n",
    "tasas_meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasas_meses_values = df[\"MES\"].value_counts().index\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.barplot(x=tasas_meses_values, y=tasas_meses[\"Tasa (%)\"], color=\"blue\", alpha=0.75)\n",
    "plt.title(\"Tasa de Retraso por Mes\")\n",
    "plt.ylabel(\"Tasa de Retraso [%]\", fontsize=12)\n",
    "plt.xlabel(\"Meses\", fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylim(0, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasas_dias = calcular_tasa(df, \"DIANOM\")\n",
    "tasas_dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasas_dias_values = df[\"DIANOM\"].value_counts().index\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=tasas_dias_values, y=tasas_dias[\"Tasa (%)\"], color=\"blue\", alpha=0.75)\n",
    "plt.title(\"Tasa de Retraso por Día\")\n",
    "plt.ylabel(\"Tasa de Retraso [%]\", fontsize=12)\n",
    "plt.xlabel(\"Días\", fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylim(0, 7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasas_temporada = calcular_tasa(df, \"temporada_alta\")\n",
    "tasas_temporada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasas_temporada_values = df[\"temporada_alta\"].value_counts().index\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.barplot(x=tasas_temporada_values, y=tasas_temporada[\"Tasa (%)\"])\n",
    "plt.title(\"Tasa de Retraso por Temporada\")\n",
    "plt.ylabel(\"Tasa de Retraso [%]\", fontsize=12)\n",
    "plt.xlabel(\"Temporada\", fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylim(0, 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasas_tipovuelo = calcular_tasa(df, \"TIPOVUELO\")\n",
    "tasas_tipovuelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasas_tipovuelo_values = df[\"TIPOVUELO\"].value_counts().index\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.barplot(x=tasas_tipovuelo_values, y=tasas_tipovuelo[\"Tasa (%)\"])\n",
    "plt.title(\"Tasa de Retraso por Tipo de Vuelo\")\n",
    "plt.ylabel(\"Tasa de Retraso [%]\", fontsize=12)\n",
    "plt.xlabel(\"Tipo de Vuelo\", fontsize=12)\n",
    "plt.ylim(0, 7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasa_periododia = calcular_tasa(df, \"periodo_dia\")\n",
    "tasa_periododia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasas_periodo_values = df[\"periodo_dia\"].value_counts().index\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.barplot(x=tasas_periodo_values, y=tasa_periododia[\"Tasa (%)\"])\n",
    "plt.title(\"Tasa de Retraso por Periodo\")\n",
    "plt.ylabel(\"Tasa de Retraso [%]\", fontsize=12)\n",
    "plt.xlabel(\"Tipo de Periodo\", fontsize=12)\n",
    "plt.ylim(3, 7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Qué variables esperarías que más influyeran en predecir atrasos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me parece que las que más podrían influir serían:\n",
    "* **Aerolíneas**: Dependiendo de la calidad de gestión de cada aerolínea puede ser que afecte en sus programaciones. También puede que afecte el tipo de aerolínea, si es una low cost por ejemplo, estas llevan menos equipaje ya que es un costo extra para cada pasajero por lo que el tiempo de carga es menor, corriendo menor riesgo de retraso. \n",
    "* **Tipo de Vuelo**: esto puede afectar en cómo esté el clima del país de destino. Por ejemplo si se tiene que volar a argentina y se tiene que cruzar por la cordillera y hay un mal clima, es posible que se tenga que esperar un rato para poder salir.\n",
    "* **Mes**: Esto va un poco de la mano con lo anterior, si es que es un mes del año donde el clima no es lo suficientemente adecuado, se tendría que esperar.  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Entrena uno o varios modelos (usando el/los algoritmo(s) que prefieras) para estimar la probabilidad de atraso de un vuelo. Siéntete libre de generar variables adicionales y/o complementar con variables externas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = df[[\"OPERA\", \"MES\", \"TIPOVUELO\", \"SIGLADES\", \"DIANOM\", \"atraso_15\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = pd.concat(\n",
    "    [\n",
    "        pd.get_dummies(data[\"OPERA\"], prefix=\"OPERA\"),\n",
    "        pd.get_dummies(data[\"TIPOVUELO\"], prefix=\"TIPOVUELO\"),\n",
    "        pd.get_dummies(data[\"MES\"], prefix=\"MES\"),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "label = data[\"atraso_15\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train_reg, x_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    features, label, test_size=0.33, random_state=42, shuffle=True, stratify=label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train_reg.shape, x_test_reg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train_reg.value_counts(\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test_reg.value_counts(\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilizando Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logReg = LogisticRegression()\n",
    "modelreg = logReg.fit(x_train_reg, y_train_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = modelreg.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_reg, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test_reg, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilizando XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelxgb1 = xgb.XGBClassifier(random_state=1, learning_rate=0.01)\n",
    "modelxgb1 = modelxgb1.fit(x_train_reg, y_train_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_predxgb = modelxgb1.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_reg, y_predxgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test_reg, y_predxgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilizando XGBoost dejando Features más importantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelxgb1.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 10))\n",
    "plot_importance(modelxgb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_importantes = features[\n",
    "    [\n",
    "        \"MES_7\",\n",
    "        \"TIPOVUELO_I\",\n",
    "        \"OPERA_Copa Air\",\n",
    "        \"OPERA_Latin American Wings\",\n",
    "        \"MES_12\",\n",
    "        \"OPERA_Grupo LATAM\",\n",
    "        \"MES_10\",\n",
    "        \"OPERA_JetSmart SPA\",\n",
    "        \"OPERA_Air Canada\",\n",
    "        \"MES_9\",\n",
    "        \"OPERA_American Airlines\",\n",
    "    ]\n",
    "]\n",
    "labels_ = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(\n",
    "    features_importantes, labels_, test_size=0.33, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelxgb = xgb.XGBClassifier(\n",
    "    random_state=1, learning_rate=0.01, subsample=1, max_depth=10\n",
    ")\n",
    "modelxgb = modelxgb.fit(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_predxgb = modelxgb.predict(x_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas XGBoost dejando Features más importantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test2, y_predxgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test2, y_predxgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evalúa tu modelo. ¿Qué performance tiene? ¿Qué métricas usaste para evaluar esa performance y por qué? ¿Por qué elegiste ese algoritmo en particular? ¿Qué variables son las que más influyen en la predicción? ¿Cómo podrías mejorar laperformance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos utilizados en la sección anterior fueron:\n",
    "* **Regresión Logística**: Fue seleccionado ya que es el modelo más simple para poder resolver problemas de clasificación.\n",
    "* **XGBoost**: Fue seleccionado porque en general tiene un gran desempeño y entrega buenos resultados ya sea para regresión y clasificación, además es bastante rápido y facilita el tuneo de hiperparámetros.\n",
    "\n",
    "Los resultados obtenidos con ambos modelos fueron muy malos. Se utilizó matriz de confusión para validar los resultados. La cantidad de falsos negativos fue muy alta. Una de las posibles razones, la más clara, es el desbalanceo que existe en la clase 'atraso_15'. Del total de datos un 82% corresponde a no atraso y el 18% restante a atraso.\n",
    "Para poder mejorar la performance se tomaron dos decisiones, la primera aplicar un Grid Search CV sobre XGBoost para tunear de mejor manera los hiperparámetros y la segunda realizar un upsampling de la clase desbalanceada, en este caso los atrasos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"n_estimators\": [50, 100, 150],\n",
    "    \"subsample\": [0.5, 0.9],\n",
    "}\n",
    "\n",
    "# modelxgb_GridCV = GridSearchCV(modelxgb, param_grid = parameters,\n",
    "#    cv = 2, n_jobs=-1, verbose=1).fit(x_train_reg, y_train_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_predxgb_grid = modelxgb_GridCV.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# confusion_matrix(y_test_reg, y_predxgb_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[\"atraso_15\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resample\n",
    "from sklearn.utils import resample\n",
    "\n",
    "data_no_retraso = data[data[\"atraso_15\"] == 0]\n",
    "data_atraso = data[data[\"atraso_15\"] == 1]\n",
    "\n",
    "data_atraso_upsampled = resample(\n",
    "    data_atraso,\n",
    "    replace=True,  # sample with replacement\n",
    "    n_samples=30000,  # to match majority class\n",
    "    random_state=42,\n",
    ")  # reproducible results\n",
    "\n",
    "data_upsampled = pd.concat([data_no_retraso, data_atraso_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_upsampled[\"atraso_15\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_upsampled = pd.concat(\n",
    "    [\n",
    "        pd.get_dummies(data_upsampled[\"OPERA\"], prefix=\"OPERA\"),\n",
    "        pd.get_dummies(data_upsampled[\"TIPOVUELO\"], prefix=\"TIPOVUELO\"),\n",
    "        pd.get_dummies(data_upsampled[\"MES\"], prefix=\"MES\"),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "label_upsampled = data_upsampled[\"atraso_15\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    x_upsampled_train,\n",
    "    x_upsampled_test,\n",
    "    y_upsampled_train,\n",
    "    y_upsampled_test,\n",
    ") = train_test_split(\n",
    "    features_upsampled, label_upsampled, test_size=0.33, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelxgb = xgb.XGBClassifier(\n",
    "    random_state=1, learning_rate=0.01, subsample=1, max_depth=10\n",
    ")\n",
    "modelxgb.fit(x_upsampled_train, y_upsampled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_upsampled_predxgb = modelxgb.predict(x_upsampled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_upsampled_test, y_upsampled_predxgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelxgb.score(x_upsampled_test, y_upsampled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_upsampled_test, y_upsampled_predxgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando los dos métodos para incrementar la performance, se puede ver como el modelo no mejoró. Esto puede ser ya que la data creada al upsamplear no tiene ningún sentido. Si se pudiese pudiese balancear la clase tal vez los modelos tendrían un mejor desempeño."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo de Francisco\n",
    "\n",
    "Disclaimer: Tuve que adaptar algunas cosas en el código de Juan, se caía en algunas partes. Dejé comentadas las líneas que modifiqué.\n",
    "\n",
    "Si bien se me pidió escoger un modelo de Juan (e implementar mejoras sobre el **modelo**), quiero mostrar que con un entendimiento un poco más adecuado de los datos se puede mejorar la performance con un enfoque sencillo y muy directo (usando el mismo modelo).\n",
    "\n",
    "Voy a eliminar las siguientes columnas:\n",
    "\n",
    "    - dif_min: Pertinente a la label, no puedo utilizarla como variable predictora\n",
    "    - periodo_dia: Voy a dejar la hora como atributo, resumirla en 3 categorías macro no me parece beneficioso. Creo que tenemos la suficiente cantidad de datos como para no tener que simplificar el atributo, se pierde información haciéndolo.\n",
    "    - Vlo-I: Esta variable no afectó la performance, decidí eliminarla.\n",
    "    - AÑO: 2017 siempre, no aporta información discriminativa.\n",
    "    - (*)-O: Todas las columnas que son pertinentes a la operación. Voy a asumir que la información de la operación corresponde a cuando el vuelo **ya sucedio**. No va a estar disponible en los datos que queremos predecir, no puedo ocuparlas como variables predictoras\n",
    "    \n",
    "Me quedo con la label que planteó Juan. Puede cuestionarse (es una decisión importante), pero ocuparé la misma para demostrar la mejora en la performance. Además me parece sensata.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "features = df.copy()\n",
    "# elimino las columnas\n",
    "features = features.drop(\n",
    "    [\n",
    "        \"dif_min\",\n",
    "        \"periodo_dia\",\n",
    "        \"Vlo-I\",\n",
    "        \"AÑO\",\n",
    "        \"Vlo-O\",\n",
    "        \"Ori-O\",\n",
    "        \"Des-O\",\n",
    "        \"Emp-O\",\n",
    "        \"OPERA\",\n",
    "        \"SIGLAORI\",\n",
    "        \"SIGLADES\",\n",
    "        \"temporada_alta\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "label = features.pop(\"atraso_15\")\n",
    "\n",
    "# convierto las columnas fecha a datetime\n",
    "features[\"Fecha-I\"] = pd.to_datetime(features[\"Fecha-I\"])\n",
    "features[\"Fecha-O\"] = pd.to_datetime(features[\"Fecha-O\"])\n",
    "features[\"DIA-I\"] = features[\"Fecha-I\"].dt.day.values\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Las columnas Mes,Dia,DIANOM estan construidas a partir de *Fecha-O*, voy a construir las mismas variables a partir de *Fecha-I* y ocupar esas. Voy a corregir *DIANOM* cuando haya una diferencia entre *Fecha-O* y *Fecha-I*. Este paso es probablemente despreciable (son pocos los datos en que cambia el dia), pero me pareció correcto incluirlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(\n",
    "    features[features[\"DIA-I\"] != features[\"DIA\"]]\n",
    ")  # en estos casos tengo que corregir el dia de la semana, que me interesa.\n",
    "\n",
    "features[\"diff_days\"] = features[\"Fecha-O\"].dt.to_period(\"D\").astype(int) - features[\n",
    "    \"Fecha-I\"\n",
    "].dt.to_period(\"D\").astype(\n",
    "    int\n",
    ")  # .dt.days\n",
    "lista_dias = [\"Lunes\", \"Martes\", \"Miercoles\", \"Jueves\", \"Viernes\", \"Sabado\", \"Domingo\"]\n",
    "\n",
    "\n",
    "def fix_day(row):\n",
    "    nombre_dia_op = row[\"DIANOM\"]\n",
    "    resta = row[\"diff_days\"]\n",
    "    index_op = lista_dias.index(nombre_dia_op)\n",
    "    index_nuevo = (index_op - resta) % 7  # para rotar en la lista lunes->domingo\n",
    "    return lista_dias[index_nuevo]\n",
    "\n",
    "\n",
    "features.loc[features[\"DIA-I\"] != features[\"DIA\"], \"DIANOM\"] = features[\n",
    "    features[\"DIA-I\"] != features[\"DIA\"]\n",
    "].apply(fix_day, axis=1)\n",
    "features[features[\"diff_days\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[\"MES-I\"] = features[\"Fecha-I\"].dt.month\n",
    "features[\"Hora\"] = (\n",
    "    features[\"Fecha-I\"].dt.hour + features[\"Fecha-I\"].dt.minute / 60\n",
    ")  # tratamos la hora como float\n",
    "features = features.drop([\"Fecha-I\", \"Fecha-O\", \"DIA\", \"MES\", \"diff_days\"], axis=1)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = [\n",
    "    columna\n",
    "    for cont, columna in enumerate(features.columns)\n",
    "    if features.dtypes[cont] != \"float64\"\n",
    "]\n",
    "features[cols] = features[cols].astype(\"category\")\n",
    "features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "My_x_train, My_x_test, My_y_train, My_y_test = train_test_split(\n",
    "    features, label, test_size=0.33, random_state=42, shuffle=True, stratify=label\n",
    ")\n",
    "My_x_train.shape, My_x_test.shape, My_x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, selector(dtype_include=\"float64\")),\n",
    "        (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "    ]\n",
    ")\n",
    "My_x_train, My_x_test = preprocessor.fit_transform(My_x_train), preprocessor.transform(\n",
    "    My_x_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "My_modelxgb = xgb.XGBClassifier(random_state=1)\n",
    "My_modelxgb = My_modelxgb.fit(My_x_train, My_y_train)\n",
    "My_y_predxgb = My_modelxgb.predict(My_x_test)\n",
    "print(classification_report(My_y_test, My_y_predxgb))\n",
    "confusion_matrix(My_y_test, My_y_predxgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay una mejora significativa en f1-score para la clase positiva (minoría), usando el mismo modelo sin ninguna sincronizacion de parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación sugerida\n",
    "\n",
    "Creo que accuracy y f1-score no son suficientes como métricas. El desafío es determinar la probabilidad de atraso, estas métricas estan midiendo la cantidad de aciertos considerando un treshold probabilístico *arbitrario*: 0.5. Sugeriría evaluar con Roc Curve y Auc Score, que se abstraen del treshold y miden directamente sobre las probabilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "My_y_proba = My_modelxgb.predict_proba(My_x_test)\n",
    "y_proba_reg = modelreg.predict_proba(x_test_reg)\n",
    "y_proba_xgb = modelxgb1.predict_proba(x_test_reg)\n",
    "\n",
    "# roc curve for models\n",
    "fpr1, tpr1, thresh1 = roc_curve(My_y_test, My_y_proba[:, 1], pos_label=1)\n",
    "fpr_reg, tpr_reg, thresh_reg = roc_curve(y_test_reg, y_proba_reg[:, 1], pos_label=1)\n",
    "fpr_xgb, tpr_xgb, thresh_xgb = roc_curve(y_test_reg, y_proba_xgb[:, 1], pos_label=1)\n",
    "# auc scores\n",
    "auc_score1 = roc_auc_score(My_y_test, My_y_proba[:, 1])\n",
    "auc_score_reg = roc_auc_score(y_test_reg, y_proba_reg[:, 1])\n",
    "auc_score_xgb = roc_auc_score(y_test_reg, y_proba_xgb[:, 1])\n",
    "\n",
    "print(\"My Method:\", auc_score1)\n",
    "print(\"Juan Logistic Regression:\", auc_score_reg)\n",
    "print(\"Juan Xgboost:\", auc_score_xgb)\n",
    "\n",
    "plt.plot(fpr1, tpr1, linestyle=\"--\", color=\"orange\", label=\"My Method\")\n",
    "plt.plot(\n",
    "    fpr_reg,\n",
    "    tpr_reg,\n",
    "    linestyle=\"--\",\n",
    "    color=\"blue\",\n",
    "    label=\"Juan Logistic Regression\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.plot(\n",
    "    fpr_xgb, tpr_xgb, linestyle=\"--\", color=\"black\", label=\"Juan Xgboost\", alpha=0.5\n",
    ")\n",
    "\n",
    "# title\n",
    "plt.title(\"ROC curve\")\n",
    "# x label\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "# y label\n",
    "plt.ylabel(\"True Positive rate\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se nota una mejora en la performance.\n",
    "\n",
    "## Para seguir mejorando el enfoque\n",
    "Hay varias cosas que hacer, lo más directo es sincronizar parámetros o probar distintos modelos (lightgbm suele darme buenos resultados). En mi experiencia, sin embargo, esto suele traer mejoras marginales.\n",
    "\n",
    "Creo que hay 2 cosas que podría traer mejoras importantes al sistema:\n",
    "\n",
    "    - Label: El método que estamos planteando para escoger la label. Aquí estamos perdiendo información sobre vuelos con atrasos más grandes que otros. Esta información puede ser importante y sería interesante incluirla. Si es que no lograra determinar por mi mismo cual es la mejor manera, consideraría hablar con el cliente sobre que es lo que ellos consideran atraso (nosotros (Juan) lo definimos como > 15min)\n",
    "    \n",
    "    - Enriquecimiento: Sinceramente no sé nada del rubro de las aerolíneas. Sospecho que uno de los factores más influyentes en los atrasos son las variables meteorológicas. Haría un enriquecimiento con estas variables de acuerdo a la ruta (orig-dest) y la (Fecha-I), ¿qué clima está pronosticado?\n",
    "    \n",
    "    - Time Series: ¿Son los datos independientes? después de todo, esto es en esencia una Serie de Tiempo, quizás la presencia de atrasos en cierto momento puede ayudar a determinar si van a haber atrasos en un futuro cercano. (Vuelos afectados por el mismo fenómeno). Esto me faltó por explorar.\n",
    "        - Si interpretamos esto como una Serie de Tiempo, habría que cambiar la metodología. El conjunto de test debiese ser el último período de la Serie y debiésemos poder predecir usando los datos históricos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardamos el modelo para ser usado por la api\n",
    "import joblib\n",
    "\n",
    "My_modelxgb.save_model(\"../objects/model.json\")\n",
    "joblib.dump(preprocessor, \"../objects/preprocessor.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "506bbbdf337b852ab49ce9a9d1daf46dbd51ffc4a3d1d2ad87f9a417a50ab5fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
